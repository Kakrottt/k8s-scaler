apiVersion: apps/v1
kind: Deployment
metadata:
  name: fake-prometheus
  namespace: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: fake-prometheus
  template:
    metadata:
      labels:
        app: fake-prometheus
    spec:
      containers:
        - name: fake-prometheus
          image: python:3.11-slim
          command: ["python", "-u", "-c"]
          args:
            - |
              import json, os
              from http.server import BaseHTTPRequestHandler, HTTPServer

              class H(BaseHTTPRequestHandler):
                  def do_GET(self):
                      latency = os.getenv("LATENCY_MS", "450")
                      res = {
                          "status": "success",
                          "data": {
                              "result": [
                                  {"value": [0, latency]}
                              ]
                          }
                      }
                      self.send_response(200)
                      self.send_header("Content-Type", "application/json")
                      self.end_headers()
                      self.wfile.write(json.dumps(res).encode())

              HTTPServer(("0.0.0.0", 9090), H).serve_forever()
          env:
            - name: LATENCY_MS
              value: "450" # change this to simulate high/low latency
          ports:
            - containerPort: 9090
---
apiVersion: v1
kind: Service
metadata:
  name: fake-prometheus
  namespace: demo
spec:
  selector:
    app: fake-prometheus
  ports:
    - name: http
      port: 9090
      targetPort: 9090
